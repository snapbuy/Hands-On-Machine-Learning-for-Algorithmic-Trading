{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Order Book Data: NASDAQ ITCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary source of market data is the order book, which is continuously updated in real-time throughout the day to reflect all trading activity. Exchanges typically offer this data as a real-time service and may provide some historical data for free.\n",
    "\n",
    "The trading activity is reflected in numerous messages about trade orders sent by market participants. These messages typically conform to the electronic Financial Information eXchange (FIX) communications protocol for real-time exchange of securities transactions and market data or a native exchange protocol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The FIX Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like SWIFT is the message protocol for back-office (example, for trade-settlement) messaging, the [FIX protocol](https://www.fixtrading.org/standards/) is the de facto messaging standard for communication before and during, trade execution between exchanges, banks, brokers, clearing firms, and other market participants. Fidelity Investments and Salomon Brothers introduced FIX in 1992 to facilitate electronic communication between broker-dealers and institutional clients who by then exchanged information over the phone.\n",
    "\n",
    "It became popular in global equity markets before expanding into foreign exchange, fixed income and derivatives markets, and further into post-trade to support straight-through processing. Exchanges provide access to FIX messages as a real-time data feed that is parsed by algorithmic traders to track market activity and, for example, identify the footprint of market participants and anticipate their next move. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nasdaq TotalView-ITCH Order Book data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While FIX has a dominant large market share, exchanges also offer native protocols. The Nasdaq offers a [TotalView ITCH direct data-feed protocol](http://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/NQTVITCHspecification.pdf) that allows subscribers to track \n",
    "individual orders for equity instruments from placement to execution or cancellation.\n",
    "\n",
    "As a result, it allows for the reconstruction of the order book that keeps track of the list of active-limit buy and sell orders for a specific security or financial instrument. The order book reveals the market depth throughout the day by listing the number of shares being bid or offered at each price point. It may also identify the market participant responsible for specific buy and sell orders unless it is placed anonymously. Market depth is a key indicator of liquidity and the potential price impact of sizable market orders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ITCH v5.0 specification declares over 20 message types related to system events, stock characteristics, the placement and modification of limit orders, and trade execution. It also contains information about the net order imbalance before the open and closing cross."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:04:35.998101Z",
     "start_time": "2018-12-25T19:04:35.989183Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urljoin\n",
    "from clint.textui import progress\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from struct import unpack\n",
    "from collections import namedtuple, Counter\n",
    "from datetime import timedelta\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NASDAQ ITCH Data from FTP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nasdaq offers [samples](ftp://emi.nasdaq.com/ITCH/) of daily binary files for several months. \n",
    "\n",
    "We are now going to illustrates how to parse a sample file of ITCH messages and reconstruct both the executed trades and the order book for any given tick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly large and running the entire example can take a lot of time and require substantial memory (16GB+). Also, the sample file used in this example may no longer be available because NASDAQ occasionaly updates the sample files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the frequency of the most common message types for the sample file date March 29, 2018:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name                    | Offset  | Length  | Value      | Notes                                                                                |\n",
    "|-------------------------|---------|---------|------------|--------------------------------------------------------------------------------------|\n",
    "| Message Type            | 0       | 1       | S          | System Event Message                                                                 |\n",
    "| Stock Locate            | 1       | 2       | Integer    | Always 0                                                                             |\n",
    "| Tracking Number         | 3       | 2       | Integer    | Nasdaq internal tracking number                                                      |\n",
    "| Timestamp               | 5       | 6       | Integer    | Nanoseconds since midnight                                                           |\n",
    "| Order Reference Number  | 11      | 8       | Integer    | The unique reference number assigned to the new order at the time of receipt.        |\n",
    "| Buy/Sell Indicator      | 19      | 1       | Alpha      | The type of order being added. B = Buy Order. S = Sell Order.                        |\n",
    "| Shares                  | 20      | 4       | Integer    | The total number of shares associated with the order being added to the book.        |\n",
    "| Stock                   | 24      | 8       | Alpha      | Stock symbol, right padded with spaces                                               |\n",
    "| Price                   | 32      | 4       | Price (4)  | The display price of the new order. Refer to Data Types for field processing notes.  |\n",
    "| Attribution             | 36      | 4       | Alpha      | Nasdaq Market participant identifier associated with the entered order               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store the download in a `data` subdirectory and convert the result to `hdf` format (discussed in the last section of chapter 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:16:28.970811Z",
     "start_time": "2018-12-25T17:16:28.966866Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('/Volumes/T7/git/Hands-On-Machine-Learning-for-Algorithmic-Trading/data') # set to e.g. external harddrive\n",
    "itch_store = str(data_path / 'itch.h5')\n",
    "order_book_store = data_path / 'order_book.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FTP address, filename and corresponding date used in this example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already updated from the 2018 example used in the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:16:30.190820Z",
     "start_time": "2018-12-25T17:16:30.189063Z"
    }
   },
   "outputs": [],
   "source": [
    "FTP_URL = 'ftp://emi.nasdaq.com/ITCH/Nasdaq_ITCH/'\n",
    "SOURCE_FILE = '03272019.NASDAQ_ITCH50.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:17:03.453672Z",
     "start_time": "2018-12-25T17:17:03.444627Z"
    }
   },
   "outputs": [],
   "source": [
    "def may_be_download(url):\n",
    "    \"\"\"Download & unzip ITCH data if not yet available\"\"\"\n",
    "    filename = data_path / url.split('/')[-1]\n",
    "    if not data_path.exists():\n",
    "        print('Creating directory')\n",
    "        data_path.mkdir()\n",
    "    if not filename.exists():\n",
    "        print('Downloading...', url)\n",
    "        urlretrieve(url, filename)\n",
    "    unzipped = data_path / (filename.stem + '.bin')\n",
    "    if not (data_path / unzipped).exists():\n",
    "        print('Unzipping to', unzipped)\n",
    "        with gzip.open(str(filename), 'rb') as f_in:\n",
    "            with open(unzipped, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    return unzipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download 5.1GB data that unzips to 12.9GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:06:08.577453Z",
     "start_time": "2018-12-25T19:06:08.570117Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading... ftp://emi.nasdaq.com/ITCH/Nasdaq_ITCH/03272019.NASDAQ_ITCH50.gz\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error ftp error: error_perm('550 The system cannot find the file specified. ',)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror_perm\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mftp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_ftp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'I'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mconnect_ftp\u001b[0;34m(self, user, passwd, host, port, dirs, timeout)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         return ftpwrapper(user, passwd, host, port, dirs, timeout,\n\u001b[0;32m-> 1556\u001b[0;31m                           persistent=False)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user, passwd, host, port, dirs, timeout, persistent)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0m_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mcwd\u001b[0;34m(self, dirname)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CWD '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoidcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mvoidcmd\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoidresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mvoidresp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;34m\"\"\"Expect a response beginning with '2'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mgetresp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_perm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merror_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror_perm\u001b[0m: 550 The system cannot find the file specified. ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ab12e3a4ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmay_be_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFTP_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOURCE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4c71a35e1865>\u001b[0m in \u001b[0;36mmay_be_download\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0munzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munzipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mftp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mftplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_errors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ftp error: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect_ftp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mftp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_ftp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'I'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mconnect_ftp\u001b[0;34m(self, user, passwd, host, port, dirs, timeout)\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect_ftp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         return ftpwrapper(user, passwd, host, port, dirs, timeout,\n\u001b[0;32m-> 1556\u001b[0;31m                           persistent=False)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCacheFTPHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFTPHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user, passwd, host, port, dirs, timeout, persistent)\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepalive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasswd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0m_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretrfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mcwd\u001b[0;34m(self, dirname)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m  \u001b[0;31m# does nothing, but could return error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CWD '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoidcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mvoidcmd\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;34m\"\"\"Send a command and expect a response beginning with '2'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoidresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msendport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mvoidresp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvoidresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;34m\"\"\"Expect a response beginning with '2'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml4t/lib/python3.6/ftplib.py\u001b[0m in \u001b[0;36mgetresp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_perm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merror_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error ftp error: error_perm('550 The system cannot find the file specified. ',)>"
     ]
    }
   ],
   "source": [
    "file_name = may_be_download(urljoin(FTP_URL, SOURCE_FILE))\n",
    "date = file_name.name.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITCH Format Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `struct` module for binary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ITCH tick data comes in binary format. Python provides the `struct` module (see [docs])(https://docs.python.org/3/library/struct.html) to parse binary data using format strings that identify the message elements by indicating length and type of the various components of the byte string as laid out in the specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docs:\n",
    "\n",
    "> This module performs conversions between Python values and C structs represented as Python bytes objects. This can be used in handling binary data stored in files or from network connections, among other sources. It uses Format Strings as compact descriptions of the layout of the C structs and the intended conversion to/from Python values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through the critical steps to parse the trading messages and reconstruct the order book:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining format strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser uses format strings according to the following formats dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.630040Z",
     "start_time": "2018-12-25T17:23:09.628023Z"
    }
   },
   "outputs": [],
   "source": [
    "event_codes = {'O': 'Start of Messages',\n",
    "               'S': 'Start of System Hours',\n",
    "               'Q': 'Start of Market Hours',\n",
    "               'M': 'End of Market Hours',\n",
    "               'E': 'End of System Hours',\n",
    "               'C': 'End of Messages'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.841397Z",
     "start_time": "2018-12-25T17:23:09.835447Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = {'primary_market_maker': {'Y': 1, 'N': 0},\n",
    "            'printable'           : {'Y': 1, 'N': 0},\n",
    "            'buy_sell_indicator'  : {'B': 1, 'S': -1},\n",
    "            'cross_type'          : {'O': 0, 'C': 1, 'H': 2},\n",
    "            'imbalance_direction' : {'B': 0, 'S': 1, 'N': 0, 'O': -1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.999064Z",
     "start_time": "2018-12-25T17:23:09.992338Z"
    }
   },
   "outputs": [],
   "source": [
    "formats = {\n",
    "    ('integer', 2): 'H',\n",
    "    ('integer', 4): 'I',\n",
    "    ('integer', 6): '6s',\n",
    "    ('integer', 8): 'Q',\n",
    "    ('alpha', 1)  : 's',\n",
    "    ('alpha', 2)  : '2s',\n",
    "    ('alpha', 4)  : '4s',\n",
    "    ('alpha', 8)  : '8s',\n",
    "    ('price_4', 4): 'I',\n",
    "    ('price_8', 8): 'Q',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create message specs for binary data parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ITCH parser relies on message specifications that we create in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Message Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `message_types.xlxs` contains the message type specs as laid out in the [documentation](https://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/NQTVITCHSpecification.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:19.798092Z",
     "start_time": "2018-12-25T18:36:19.783135Z"
    }
   },
   "outputs": [],
   "source": [
    "message_data = (pd.read_excel('message_types.xlsx',\n",
    "                              sheet_name='messages',\n",
    "                              encoding='latin1')\n",
    "                .sort_values('id')\n",
    "                .drop('id', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `clean_message_types()` just runs a few basic string cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:18.635039Z",
     "start_time": "2018-12-25T18:36:18.630282Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_message_types(df):\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    df.value = df.value.str.strip()\n",
    "    df.name = (df.name\n",
    "               .str.strip() # remove whitespace\n",
    "               .str.lower()\n",
    "               .str.replace(' ', '_')\n",
    "               .str.replace('-', '_')\n",
    "               .str.replace('/', '_'))\n",
    "    df.notes = df.notes.str.strip()\n",
    "    df['message_type'] = df.loc[df.name == 'message_type', 'value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types = clean_message_types(message_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Message Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract message type codes and names so we can later make the results more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:22.741964Z",
     "start_time": "2018-12-25T18:36:22.734576Z"
    }
   },
   "outputs": [],
   "source": [
    "message_labels = (message_types.loc[:, ['message_type', 'notes']]\n",
    "                  .dropna()\n",
    "                  .rename(columns={'notes': 'name'}))\n",
    "message_labels.name = (message_labels.name\n",
    "                       .str.lower()\n",
    "                       .str.replace('message', '')\n",
    "                       .str.replace('.', '')\n",
    "                       .str.strip().str.replace(' ', '_'))\n",
    "# message_labels.to_csv('message_labels.csv', index=False)\n",
    "message_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize specification details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each message consists of several fields that are defined by offset, length and type of value. The `struct` module will use this format information to parse the binary source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:57.493706Z",
     "start_time": "2018-12-25T18:36:56.614416Z"
    }
   },
   "outputs": [],
   "source": [
    "message_types.message_type = message_types.message_type.ffill()\n",
    "message_types = message_types[message_types.name != 'message_type']\n",
    "message_types.value = (message_types.value\n",
    "                       .str.lower()\n",
    "                       .str.replace(' ', '_')\n",
    "                       .str.replace('(', '')\n",
    "                       .str.replace(')', ''))\n",
    "message_types.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, persist/reload from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types.to_csv('message_types.csv', index=False)\n",
    "message_types = pd.read_csv('message_types.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser translates the message specs into format strings and namedtuples that capture the message content. First, we create `(type, length)` formatting tuples from ITCH specs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:25.322056Z",
     "start_time": "2018-12-25T17:29:25.291911Z"
    }
   },
   "outputs": [],
   "source": [
    "message_types.loc[:, 'formats'] = (message_types[['value', 'length']]\n",
    "                            .apply(tuple, axis=1).map(formats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we extract formatting details for alphanumerical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.058965Z",
     "start_time": "2018-12-25T17:29:27.044699Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_fields = message_types[message_types.value == 'alpha'].set_index('name')\n",
    "alpha_msgs = alpha_fields.groupby('message_type')\n",
    "alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n",
    "alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate message classes as named tuples and format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.755034Z",
     "start_time": "2018-12-25T17:29:27.722828Z"
    }
   },
   "outputs": [],
   "source": [
    "message_fields, fstring = {}, {}\n",
    "for t, message in message_types.groupby('message_type'):\n",
    "    message_fields[t] = namedtuple(typename=t, field_names=message.name.tolist())\n",
    "    fstring[t] = '>' + ''.join(message.formats.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields of `alpha` type (alphanumeric) require post-processing as defined in the `format_alpha` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:28.145192Z",
     "start_time": "2018-12-25T17:29:28.131796Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_alpha(mtype, data):\n",
    "    \"\"\"Process byte strings of type alpha\"\"\"\n",
    "\n",
    "    for col in alpha_formats.get(mtype).keys():\n",
    "        if mtype != 'R' and col == 'stock':\n",
    "            data = data.drop(col, axis=1)\n",
    "            continue\n",
    "        data.loc[:, col] = data.loc[:, col].str.decode(\"utf-8\").str.strip()\n",
    "        if encoding.get(col):\n",
    "            data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Binary Message Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary file for a single day contains over 350,000,000 messages worth over 12 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.620911Z",
     "start_time": "2018-12-25T17:29:45.606916Z"
    }
   },
   "outputs": [],
   "source": [
    "def store_messages(m):\n",
    "    \"\"\"Handle occasional storing of all messages\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        for mtype, data in m.items():\n",
    "            # convert to DataFrame\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "            # parse timestamp info\n",
    "            data.timestamp = data.timestamp.apply(int.from_bytes, byteorder='big')\n",
    "            data.timestamp = pd.to_timedelta(data.timestamp)\n",
    "\n",
    "            # apply alpha formatting\n",
    "            if mtype in alpha_formats.keys():\n",
    "                data = format_alpha(mtype, data)\n",
    "\n",
    "            s = alpha_length.get(mtype)\n",
    "            if s:\n",
    "                s = {c: s.get(c) for c in data.columns}\n",
    "            dc = ['stock_locate']\n",
    "            if m == 'R':\n",
    "                dc.append('stock')\n",
    "            store.append(mtype,\n",
    "                         data,\n",
    "                         format='t',\n",
    "                         min_itemsize=s,\n",
    "                         data_columns=dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.638871Z",
     "start_time": "2018-12-25T17:29:45.623938Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = {}\n",
    "message_count = 0\n",
    "message_type_counter = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script appends the parsed result iteratively to a file in the fast HDF5 format using the `store_messages()` function we just defined to avoid memory constraints (see last section in chapter 2 for more on this format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following (simplified) code processes the binary file and produces the parsed orders stored by message type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:59:34.870288Z",
     "start_time": "2018-12-25T17:29:45.640518Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with file_name.open('rb') as data:\n",
    "    while True:\n",
    "        \n",
    "        # determine message size in bytes\n",
    "        message_size = int.from_bytes(data.read(2), byteorder='big', signed=False)\n",
    "        \n",
    "        # get message type by reading first byte\n",
    "        message_type = data.read(1).decode('ascii')\n",
    "        \n",
    "        # create data structure to capture result\n",
    "        if not messages.get(message_type):\n",
    "            messages[message_type] = []\n",
    "\n",
    "        message_type_counter.update([message_type])\n",
    "\n",
    "        # read & store message\n",
    "        record = data.read(message_size - 1)\n",
    "        message = message_fields[message_type]._make(unpack(fstring[message_type], record))\n",
    "        messages[message_type].append(message)\n",
    "        \n",
    "        # deal with system events\n",
    "        if message_type == 'S':\n",
    "            timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "            print('\\n', event_codes.get(message.event_code.decode('ascii'), 'Error'))\n",
    "            print('\\t{0}\\t{1:,.0f}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                         message_count))\n",
    "            if message.event_code.decode('ascii') == 'C':\n",
    "                store_messages(messages)\n",
    "                break\n",
    "\n",
    "        message_count += 1\n",
    "        if message_count % 2.5e7 == 0:\n",
    "            timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "            print('\\t{0}\\t{1:,.0f}\\t{2}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                                message_count,\n",
    "                                                timedelta(seconds=time() - start)))\n",
    "            store_messages(messages)\n",
    "            messages = {}\n",
    "            \n",
    "        \n",
    "print(timedelta(seconds=time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Trading Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Message Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:03.560168Z",
     "start_time": "2018-12-25T18:38:03.551636Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = pd.Series(message_type_counter).to_frame('# Trades')\n",
    "counter['Message Type'] = counter.index.map(message_labels.set_index('message_type').name.to_dict())\n",
    "counter = counter[['Message Type', '# Trades']].sort_values('# Trades', ascending=False)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:05.819908Z",
     "start_time": "2018-12-25T18:38:05.810713Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    store.put('summary', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Equities by Traded Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.781356Z",
     "start_time": "2018-12-25T18:38:21.989429Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n",
    "    trades = store['P'].append(store['Q'].rename(columns={'cross_price': 'price'}), sort=False).merge(stocks)\n",
    "trades['value'] = trades.shares.mul(trades.price)\n",
    "trades['value_share'] = trades.value.div(trades.value.sum())\n",
    "trade_summary = trades.groupby('stock').value_share.sum().sort_values(ascending=False)\n",
    "trade_summary.iloc[:50].plot.bar(figsize=(14, 6), color='darkblue', title='Share of Traded Value')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Order Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.784560Z",
     "start_time": "2018-12-25T18:38:22.782597Z"
    }
   },
   "outputs": [],
   "source": [
    "stock = 'AAPL'\n",
    "order_dict = {-1: 'sell', 1: 'buy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed messages allow us to rebuild the order flow for the given day. The 'R' message type contains a listing of all stocks traded during a given day, including information about initial public offerings (IPOs) and trading restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the day, new orders are added, and orders that are executed and canceled are removed from the order book. The proper accounting for messages that reference orders placed on a prior date would require tracking the order book over multiple days, but we are ignoring this aspect here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all messages for given stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_messages()` function illustrates how to collect the orders for a single stock that affects trading (refer to the ITCH specification for details about each message):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.794673Z",
     "start_time": "2018-12-25T18:38:22.785605Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_messages(date, stock=stock):\n",
    "    \"\"\"Collect trading messages for given stock\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        stock_locate = store.select('R', where='stock = stock').stock_locate.iloc[0]\n",
    "        target = 'stock_locate = stock_locate'\n",
    "\n",
    "        data = {}\n",
    "        # trading message types\n",
    "        messages = ['A', 'F', 'E', 'C', 'X', 'D', 'U', 'P', 'Q']\n",
    "        for m in messages:\n",
    "            data[m] = store.select(m, where=target).drop('stock_locate', axis=1).assign(type=m)\n",
    "\n",
    "    order_cols = ['order_reference_number', 'buy_sell_indicator', 'shares', 'price']\n",
    "    orders = pd.concat([data['A'], data['F']], sort=False, ignore_index=True).loc[:, order_cols]\n",
    "\n",
    "    for m in messages[2: -3]:\n",
    "        data[m] = data[m].merge(orders, how='left')\n",
    "\n",
    "    data['U'] = data['U'].merge(orders, how='left',\n",
    "                                right_on='order_reference_number',\n",
    "                                left_on='original_order_reference_number',\n",
    "                                suffixes=['', '_replaced'])\n",
    "\n",
    "    data['Q'].rename(columns={'cross_price': 'price'}, inplace=True)\n",
    "    data['X']['shares'] = data['X']['cancelled_shares']\n",
    "    data['X'] = data['X'].dropna(subset=['price'])\n",
    "\n",
    "    data = pd.concat([data[m] for m in messages], ignore_index=True, sort=False)\n",
    "    data['date'] = pd.to_datetime(date, format='%m%d%Y')\n",
    "    data.timestamp = data['date'].add(data.timestamp)\n",
    "    data = data[data.printable != 0]\n",
    "\n",
    "    drop_cols = ['tracking_number', 'order_reference_number', 'original_order_reference_number',\n",
    "                 'cross_type', 'new_order_reference_number', 'attribution', 'match_number',\n",
    "                 'printable', 'date', 'cancelled_shares']\n",
    "    return data.drop(drop_cols, axis=1).sort_values('timestamp').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.320030Z",
     "start_time": "2018-12-25T18:38:22.796992Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = get_messages(date=date)\n",
    "messages.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.453686Z",
     "start_time": "2018-12-25T18:38:31.322040Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    key = '{}/messages'.format(stock)\n",
    "    store.put(key, messages)\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Trading Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructing successful trades, that is, orders that are executed as opposed to those that were canceled from trade-related message types, C, E, P, and Q, is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.458668Z",
     "start_time": "2018-12-25T18:38:31.455129Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trades(m):\n",
    "    \"\"\"Combine C, E, P and Q messages into trading records\"\"\"\n",
    "    trade_dict = {'executed_shares': 'shares', 'execution_price': 'price'}\n",
    "    cols = ['timestamp', 'executed_shares']\n",
    "    trades = pd.concat([m.loc[m.type == 'E', cols + ['price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'C', cols + ['execution_price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'P', ['timestamp', 'price', 'shares']],\n",
    "                        m.loc[m.type == 'Q', ['timestamp', 'price', 'shares']].assign(cross=1),\n",
    "                        ], sort=False).dropna(subset=['price']).fillna(0)\n",
    "    return trades.set_index('timestamp').sort_index().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.707339Z",
     "start_time": "2018-12-25T18:38:31.459640Z"
    }
   },
   "outputs": [],
   "source": [
    "trades = get_trades(messages)\n",
    "print(trades.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.716334Z",
     "start_time": "2018-12-25T18:38:31.708217Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    store.put('{}/trades'.format(stock), trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order book keeps track of limit orders, and the various price levels for buy and sell orders constitute the depth of the order book. To reconstruct the order book for a given level of depth requires the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_orders()` function accumulates sell orders in ascending, and buy orders in descending order for a given timestamp up to the desired level of depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.727288Z",
     "start_time": "2018-12-25T18:38:31.717324Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_orders(orders, buysell, nlevels):\n",
    "    \"\"\"Add orders up to desired depth given by nlevels;\n",
    "        sell in ascending, buy in descending order\n",
    "    \"\"\"\n",
    "    new_order = []\n",
    "    items = sorted(orders.copy().items())\n",
    "    if buysell == 1:\n",
    "        items = reversed(items)  \n",
    "    for i, (p, s) in enumerate(items, 1):\n",
    "        new_order.append((p, s))\n",
    "        if i == nlevels:\n",
    "            break\n",
    "    return orders, new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.738494Z",
     "start_time": "2018-12-25T18:38:31.728222Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_orders(orders, append=False):\n",
    "    cols = ['price', 'shares']\n",
    "    for buysell, book in orders.items():\n",
    "        df = (pd.concat([pd.DataFrame(data=data,\n",
    "                                     columns=cols)\n",
    "                         .assign(timestamp=t) \n",
    "                         for t, data in book.items()]))\n",
    "        key = '{}/{}'.format(stock, order_dict[buysell])\n",
    "        df.loc[:, ['price', 'shares']] = df.loc[:, ['price', 'shares']].astype(int)\n",
    "        with pd.HDFStore(order_book_store) as store:\n",
    "            if append:\n",
    "                store.append(key, df.set_index('timestamp'), format='t')\n",
    "            else:\n",
    "                store.put(key, df.set_index('timestamp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over all ITCH messages and process orders and their replacements as required by the specification (this can take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.364384Z",
     "start_time": "2018-12-25T18:38:31.739374Z"
    }
   },
   "outputs": [],
   "source": [
    "order_book = {-1: {}, 1: {}}\n",
    "current_orders = {-1: Counter(), 1: Counter()}\n",
    "message_counter = Counter()\n",
    "nlevels = 100\n",
    "\n",
    "start = time()\n",
    "for message in messages.itertuples():\n",
    "    i = message[0]\n",
    "    if i % 1e5 == 0 and i > 0:\n",
    "        print('{:,.0f}\\t\\t{}'.format(i, timedelta(seconds=time() - start)))\n",
    "        save_orders(order_book, append=True)\n",
    "        order_book = {-1: {}, 1: {}}\n",
    "        start = time()\n",
    "    if np.isnan(message.buy_sell_indicator):\n",
    "        continue\n",
    "    message_counter.update(message.type)\n",
    "\n",
    "    buysell = message.buy_sell_indicator\n",
    "    price, shares = None, None\n",
    "\n",
    "    if message.type in ['A', 'F', 'U']:\n",
    "        price = int(message.price)\n",
    "        shares = int(message.shares)\n",
    "\n",
    "        current_orders[buysell].update({price: shares})\n",
    "        current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "        order_book[buysell][message.timestamp] = new_order\n",
    "\n",
    "    if message.type in ['E', 'C', 'X', 'D', 'U']:\n",
    "        if message.type == 'U':\n",
    "            if not np.isnan(message.shares_replaced):\n",
    "                price = int(message.price_replaced)\n",
    "                shares = -int(message.shares_replaced)\n",
    "        else:\n",
    "            if not np.isnan(message.price):\n",
    "                price = int(message.price)\n",
    "                shares = -int(message.shares)\n",
    "\n",
    "        if price is not None:\n",
    "            current_orders[buysell].update({price: shares})\n",
    "            if current_orders[buysell][price] <= 0:\n",
    "                current_orders[buysell].pop(price)\n",
    "            current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "            order_book[buysell][message.timestamp] = new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.367586Z",
     "start_time": "2018-12-25T18:59:13.365257Z"
    }
   },
   "outputs": [],
   "source": [
    "message_counter = pd.Series(message_counter)\n",
    "print(message_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.386058Z",
     "start_time": "2018-12-25T18:59:13.368397Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Book Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:34.898346Z",
     "start_time": "2018-12-25T18:59:13.387216Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    buy = store['{}/buy'.format(stock)].reset_index().drop_duplicates()\n",
    "    sell = store['{}/sell'.format(stock)].reset_index().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price to Decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:35.213809Z",
     "start_time": "2018-12-25T18:59:34.901354Z"
    }
   },
   "outputs": [],
   "source": [
    "buy.price = buy.price.mul(1e-4)\n",
    "sell.price = sell.price.mul(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:42.096414Z",
     "start_time": "2018-12-25T18:59:35.214763Z"
    }
   },
   "outputs": [],
   "source": [
    "percentiles = [.01, .02, .1, .25, .75, .9, .98, .99]\n",
    "pd.concat([buy.price.describe(percentiles=percentiles).to_frame('buy'),\n",
    "           sell.price.describe(percentiles=percentiles).to_frame('sell')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:44.810646Z",
     "start_time": "2018-12-25T18:59:42.097253Z"
    }
   },
   "outputs": [],
   "source": [
    "buy = buy[buy.price > buy.price.quantile(.01)]\n",
    "sell = sell[sell.price < sell.price.quantile(.99)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buy-Sell Order Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of orders at different price levels, highlighted in the following screenshot using different intensities for buy and sell orders, visualizes the depth of liquidity at any given point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of limit order prices was weighted toward buy orders at higher prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:03.115714Z",
     "start_time": "2018-12-25T19:03:03.109202Z"
    }
   },
   "outputs": [],
   "source": [
    "market_open='0930'\n",
    "market_close = '1600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:37.441700Z",
     "start_time": "2018-12-25T19:03:26.117795Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "hist_kws = {'linewidth': 1, 'alpha': .5}\n",
    "sns.distplot(buy.set_index('timestamp').between_time(market_open, market_close).price, ax=ax, label='Buy', kde=False, hist_kws=hist_kws)\n",
    "sns.distplot(sell.set_index('timestamp').between_time(market_open, market_close).price, ax=ax, label='Sell', kde=False, hist_kws=hist_kws)\n",
    "plt.legend(fontsize=10)\n",
    "plt.title('Limit Order Price Distribution', fontsize=14)\n",
    "ax.set_yticklabels(['{:,}'.format(int(y/1000)) for y in ax.get_yticks().tolist()])\n",
    "ax.set_xticklabels(['${:,}'.format(int(x)) for x in ax.get_xticks().tolist()])\n",
    "plt.xlabel('Price', fontsize=12)\n",
    "plt.ylabel('Shares (\\'000)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/price_distribution', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Book Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:45.701297Z",
     "start_time": "2018-12-25T19:03:45.696600Z"
    }
   },
   "outputs": [],
   "source": [
    "utc_offset = timedelta(hours=4)\n",
    "depth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:48.330392Z",
     "start_time": "2018-12-25T19:03:46.059173Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buy_per_min = (buy\n",
    "               .groupby([pd.Grouper(key='timestamp', freq='Min'), 'price'])\n",
    "               .shares\n",
    "               .sum()\n",
    "               .apply(np.log)\n",
    "               .to_frame('shares')\n",
    "               .reset_index('price')\n",
    "               .between_time(market_open, market_close)\n",
    "               .groupby(level='timestamp', as_index=False, group_keys=False)\n",
    "               .apply(lambda x: x.nlargest(columns='price', n=depth))\n",
    "               .reset_index())\n",
    "buy_per_min.timestamp = buy_per_min.timestamp.add(utc_offset).astype(int)\n",
    "buy_per_min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:50.748806Z",
     "start_time": "2018-12-25T19:03:48.331693Z"
    }
   },
   "outputs": [],
   "source": [
    "sell_per_min = (sell\n",
    "                .groupby([pd.Grouper(key='timestamp', freq='Min'), 'price'])\n",
    "                .shares\n",
    "                .sum()\n",
    "                .apply(np.log)\n",
    "                .to_frame('shares')\n",
    "                .reset_index('price')\n",
    "                .between_time(market_open, market_close)\n",
    "                .groupby(level='timestamp', as_index=False, group_keys=False)\n",
    "                .apply(lambda x: x.nsmallest(columns='price', n=depth))\n",
    "                .reset_index())\n",
    "\n",
    "sell_per_min.timestamp = sell_per_min.timestamp.add(utc_offset).astype(int)\n",
    "sell_per_min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:51.440194Z",
     "start_time": "2018-12-25T19:03:51.399025Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    trades = store['{}/trades'.format(stock)]\n",
    "trades.price = trades.price.mul(1e-4)\n",
    "trades = trades[trades.cross == 0].between_time(market_open, market_close)\n",
    "\n",
    "trades_per_min = (trades\n",
    "                  .resample('Min')\n",
    "                  .agg({'price': 'mean', 'shares': 'sum'}))\n",
    "trades_per_min.index = trades_per_min.index.to_series().add(utc_offset).astype(int)\n",
    "trades_per_min.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the evolution of limit orders and prices throughout the trading day: the dark line tracks the prices for executed trades during market hours, whereas the red and blue dots indicate individual limit orders on a per-minute basis (see notebook for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:06:39.328578Z",
     "start_time": "2018-12-25T19:06:37.074213Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "buy_per_min.plot.scatter(x='timestamp',y='price', c='shares', ax=ax, colormap='Blues', colorbar=False, alpha=.25)\n",
    "sell_per_min.plot.scatter(x='timestamp',y='price', c='shares', ax=ax, colormap='Reds', colorbar=False, alpha=.25)\n",
    "trades_per_min.price.plot(figsize=(14, 8), c='k', ax=ax, lw=2, \n",
    "                          title=f'AAPL | {date} | Buy & Sell Limit Order Book | Depth = {depth}')\n",
    "\n",
    "xticks = [datetime.fromtimestamp(ts / 1e9).strftime('%H:%M') for ts in ax.get_xticks()]\n",
    "ax.set_xticklabels(xticks)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Price')\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('figures/order_book', dpi=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97def81ba15f9afa951ab749b10c15d92947112ab78062d7171aa1d2b79a81e0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('ml4t': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
